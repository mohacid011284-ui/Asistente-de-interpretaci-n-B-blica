import streamlit as st
import google.generativeai as genai
import os

# CONFIGURACI√ìN DE P√ÅGINA
st.set_page_config(page_title="Instructor B√≠blico", page_icon="üìñ", layout="wide")

# ESTILOS
st.markdown("""<style>div.stButton > button {width: 100%; border-radius: 10px; height: 3em;}</style>""", unsafe_allow_html=True)

# --- üß† EL CEREBRO (INSTRUCCIONES FIJAS) ---
# F√≠jate que el texto empieza y termina con tres comillas (""")
INSTRUCCIONES_BASE = """
ACT√öA COMO: Un Instructor de Seminario experto en Hermen√©utica.
TU FILOSOF√çA: "Permanecer en la l√≠nea". No creas significado, lo descubres.

üö® REGLAS DE INTERACCI√ìN (CR√çTICO - L√âELAS SIEMPRE):
1. **PROHIBIDO DAR DISCURSOS LARGOS:** No expliques las 3 fases de golpe. No sueltes bloques gigantes de texto.
2. **UNA COSA A LA VEZ:** Tu m√©todo es PASO A PASO.
   - Primero explicas un concepto breve (m√°ximo 3 frases).
   - Inmediatamente haces UNA pregunta o pones un ejercicio.
   - **DETENTE Y ESPERA** a que el alumno responda.
3. **NO AVANCES** a la siguiente fase hasta que el alumno haya completado la anterior.

MODO AULA (LECCIONES):
- Si el usuario inicia una lecci√≥n, da solo la definici√≥n del tema y pide un ejemplo o haz una pregunta de control.
- Ejemplo: "Hoy veremos la L√≠nea Mel√≥dica. Es el tema principal del libro. ¬øPodr√≠as decirme cu√°l crees que es el tema de Jon√°s?" (Y ESPERAS).

MODO ALUMNO (AN√ÅLISIS):
1. Pide el texto b√≠blico. -> ESPERA.
2. Pregunta por el G√©nero Literario. -> ESPERA.
3. Pregunta por el Contexto Inmediato. -> ESPERA.
4. Solo cuando la Observaci√≥n (Fase 1) est√© firme, pasas a la Teolog√≠a (Fase 2).

TU OBJETIVO: Que el alumno PIENSE, no que lea. S√© breve, directo y pedag√≥gico.
"""

# --- FUNCI√ìN PARA CARGAR EL MANUAL DESDE GITHUB ---
def get_system_prompt():
    prompt_completo = INSTRUCCIONES_BASE
    # Intentamos leer el manual que subiste a la carpeta knowledge
    ruta_manual = "knowledge/manual_completo_v2.md"
    if os.path.exists(ruta_manual):
        try:
            with open(ruta_manual, "r", encoding="utf-8") as f:
                manual_texto = f.read()
                prompt_completo += "\n\n=== MANUAL DE REFERENCIA ===\n" + manual_texto
        except:
            pass
    return prompt_completo

# --- SIDEBAR ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3389/3389081.png", width=100)
    st.title("Aula Virtual")
    st.markdown("---")
    st.link_button("Ir a Google Classroom", "https://classroom.google.com/w/ODM5MzY1NTk0Mzc5/t/all")
    st.markdown("---")
    if st.button("üóëÔ∏è Borrar Chat", type="primary"):
        st.session_state.messages = []
        st.rerun()

# --- API KEY ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("Falta la API Key en Secrets.")

# --- INICIALIZAR MODELO ---
if "model" not in st.session_state:
    prompt_final = get_system_prompt()
    st.session_state.model = genai.GenerativeModel(
        model_name="gemini-flash-latest", 
        system_instruction=prompt_final
    )

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- INTERFAZ ---
st.title("üìñ Instructor de Interpretaci√≥n B√≠blica")
st.caption("Filosof√≠a: Permanecer en la l√≠nea")

# Botones
c1, c2, c3, c4 = st.columns(4)
def click(txt): st.session_state.messages.append({"role": "user", "content": txt})
with c1: 
    if st.button("üéì Aula"): click("Iniciar Modo Aula: Lecci√≥n 1")
with c2: 
    if st.button("üìù Alumno"): click("Quiero analizar un pasaje")
with c3: 
    if st.button("üßë‚Äçüè´ Maestro"): click("Modela una interpretaci√≥n")
with c4: 
    if st.button("üîç Revisi√≥n"): click("Revisa mi trabajo seg√∫n el manual")

# Chat
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("Escribe aqu√≠..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            try:
                h = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
                chat = st.session_state.model.start_chat(history=h)
                response = chat.send_message(st.session_state.messages[-1]["content"])
                st.markdown(response.text)
                st.session_state.messages.append({"role": "model", "content": response.text})
            except Exception as e:
                st.error(f"Error: {e}")
