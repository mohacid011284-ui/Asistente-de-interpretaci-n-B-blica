import streamlit as st
import google.generativeai as genai
import os

# CONFIGURACI√ìN DE P√ÅGINA
st.set_page_config(page_title="Instructor B√≠blico", page_icon="üìñ", layout="wide")

# ESTILOS
st.markdown("""<style>div.stButton > button {width: 100%; border-radius: 10px; height: 3em;}</style>""", unsafe_allow_html=True)

# --- üß† EL CEREBRO (INSTRUCCIONES FIJAS) ---
# Las ponemos aqu√≠ directo para que nunca fallen
INSTRUCCIONES_BASE = """
ACT√öA COMO: Un Instructor de Seminario experto en Hermen√©utica.
TU FILOSOF√çA: "Permanecer en la l√≠nea". No creas significado, lo descubres.
TU LEMA: "Ni m√°s (legalismo), ni menos (liberalismo)".

TU OBJETIVO: Guiar al alumno por las 3 Fases del M√©todo Expositivo:
1. EX√âGESIS (Observaci√≥n): ¬øQu√© dice el texto? (Contexto, Gram√°tica, G√©nero).
2. TEOLOG√çA (Reflexi√≥n): ¬øC√≥mo conecta con Cristo? (Sin alegorizar, usando Tipolog√≠a, Promesa, etc).
3. APLICACI√ìN (Persuasi√≥n): ¬øQu√© demanda hoy? (Para el creyente y no creyente).

REGLAS DE ORO:
- Si el usuario pone un texto, NO des la respuesta final. Haz preguntas socr√°ticas para que √©l la descubra.
- Si el usuario pide revisi√≥n, s√© amable pero riguroso bas√°ndote en el Manual.
- Si faltan archivos de conocimiento, √∫salo lo que sepas de teolog√≠a reformada cl√°sica.
"""

# --- FUNCI√ìN PARA CARGAR EL MANUAL DESDE GITHUB ---
def get_system_prompt():
    prompt_completo = INSTRUCCIONES_BASE
    
    # Intentamos leer el manual que subiste a la carpeta knowledge
    ruta_manual = "knowledge/manual_completo_v2.md"
    
    if os.path.exists(ruta_manual):
        try:
            with open(ruta_manual, "r", encoding="utf-8") as f:
                manual_texto = f.read()
                prompt_completo += "\n\n=== MANUAL DE REFERENCIA ===\n" + manual_texto
        except:
            # Si falla al leer, seguimos con la instrucci√≥n base
            pass
    else:
        # Si no encuentra el archivo, agrega una nota para el modelo
        prompt_completo += "\n\n(NOTA: No tengo acceso al manual completo en este momento. Usar√© mi conocimiento general de hermen√©utica expositiva)."
    
    return prompt_completo

# --- SIDEBAR ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3389/3389081.png", width=100)
    st.title("Aula Virtual")
    st.markdown("---")
    st.link_button("Ir a Google Classroom", "https://classroom.google.com/w/ODM5MzY1NTk0Mzc5/t/all")
    st.markdown("---")
    if st.button("üóëÔ∏è Borrar Chat", type="primary"):
        st.session_state.messages = []
        st.rerun()

# --- API KEY ---
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("Falta la API Key en Secrets.")

# --- INICIALIZAR MODELO ---
if "model" not in st.session_state:
    # Aqu√≠ construimos el cerebro sumando Instrucciones + Manual
    prompt_final = get_system_prompt()
    
    st.session_state.model = genai.GenerativeModel(
        model_name="gemini-flash-latest", 
        system_instruction=prompt_final
    )

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- INTERFAZ ---
st.title("üìñ Instructor de Interpretaci√≥n B√≠blica")
st.caption("Filosof√≠a: Permanecer en la l√≠nea")

# Botones
c1, c2, c3, c4 = st.columns(4)
def click(txt): st.session_state.messages.append({"role": "user", "content": txt})
with c1: 
    if st.button("üéì Aula"): click("Iniciar Modo Aula: Lecci√≥n 1")
with c2: 
    if st.button("üìù Alumno"): click("Quiero analizar un pasaje")
with c3: 
    if st.button("üßë‚Äçüè´ Maestro"): click("Modela una interpretaci√≥n")
with c4: 
    if st.button("üîç Revisi√≥n"): click("Revisa mi trabajo seg√∫n el manual")

# Chat
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("Escribe aqu√≠..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with st.chat_message("assistant"):
        with st.spinner("Consultando manual..."):
            try:
                # Historial
                h = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
                chat = st.session_state.model.start_chat(history=h)
                response = chat.send_message(st.session_state.messages[-1]["content"])
                st.markdown(response.text)
                st.session_state.messages.append({"role": "model", "content": response.text})
            except Exception as e:
                st.error(f"Error: {e}")
