import streamlit as st
import google.generativeai as genai
import os

# CONFIGURACI√ìN DE LA P√ÅGINA
st.set_page_config(
    page_title="Instructor de Interpretaci√≥n B√≠blica",
    page_icon="üìñ",
    layout="wide"
)

# BARRA LATERAL (MENU)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3389/3389081.png", width=100)
    st.title("Aula Virtual")
    st.markdown("---")
    
    # ENLACES A CLASSROOM
    st.header("üîó Enlaces R√°pidos")
    # AQU√ç ESTABA EL ERROR: Me asegur√© de que esta l√≠nea tenga 4 espacios al inicio
    st.link_button("Ir a Google Classroom", "https://classroom.google.com/w/ODM5MzY1NTk0Mzc5/t/all")
    
    st.markdown("---")
    st.header("üìÇ Recursos")
    st.info("Recuerda descargar las hojas de trabajo desde Classroom antes de empezar.")

# CONFIGURACI√ìN DE LA API (SECRETA)
# En Streamlit Cloud configuraremos esto en "Secrets"
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("Falta configurar la API Key en los Secrets de Streamlit.")

# FUNCI√ìN PARA CARGAR EL SYSTEM PROMPT
def load_system_prompt():
    try:
        # Busca el archivo en la carpeta prompts
        with open("prompts/system_instruction.md", "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        return "Eres un asistente √∫til. (Error: No se encontr√≥ system_instruction.md)"

# INICIALIZAR EL MODELO
if "model" not in st.session_state:
    system_instruction = load_system_prompt()
    st.session_state.model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        system_instruction=system_instruction
    )

# INTERFAZ PRINCIPAL DE CHAT
st.title("üìñ Instructor de Interpretaci√≥n B√≠blica")
st.caption("Filosof√≠a: Permanecer en la l√≠nea | M√©todo: Expositivo")

# Historial de Chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar mensajes anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Capturar entrada del usuario
if prompt := st.chat_input("Escribe tu duda o pasaje aqu√≠..."):
    # 1. Mostrar mensaje del usuario
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. Generar respuesta
    try:
        chat = st.session_state.model.start_chat(history=[
            {"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]
        ])
        response = chat.send_message(prompt)
        
        # 3. Mostrar respuesta del AI
        with st.chat_message("assistant"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "model", "content": response.text})
        
    except Exception as e:
        st.error(f"Ocurri√≥ un error: {e}")
